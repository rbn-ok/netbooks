{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "intro_keras.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dggNSVDxGHG"
      },
      "source": [
        "# **Introducción a Keras**\r\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN-IzkRvxGHP"
      },
      "source": [
        "Keras es una librería Python especializada en redes neuronales artificiales, tanto clásicas como más modernas (redes convolucionales, redes recurrentes, etc.). Es algo más complicada de utilizar que Scikit-learn al tener una API de más bajo nivel, que requiere que el usuario defina la estructura del modelo programáticamente.\n",
        "\n",
        "Se trata de una librería Python de alto nivel para trabajar con redes neuronales artificiales. Para ello utiliza paquetes de cálculo numérico y simbólico como Theano, TensorFlow o CNTK, lo que evita al usuario tener que programar los algoritmos básicos en lenguajes de bajo nivel como C, C++ o CUDA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHmR_ZeNxGHR"
      },
      "source": [
        "Primero preparamos los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9HPEnRzxW0F"
      },
      "source": [
        "from keras.datasets.boston_housing import load_data\r\n",
        "(X, y), (X_test, y_test) = load_data()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtmWgS_pxoAk",
        "outputId": "4b2d047a-b76d-4932-c59b-f22039c42159"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi5D4jtXxq9c",
        "outputId": "5654fcb7-b628-44fe-83b2-39eac45d23a5"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcDLmGXWxs4c",
        "outputId": "a1fb5b12-4a6d-4bb3-fbcd-34cfffa5539a"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "felTDqomxvn8",
        "outputId": "9b7e9301-8940-4029-d690-f6593da877b7"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGPo6VTixGHT"
      },
      "source": [
        "Definir una red neuronal básica en Keras es sencillo. Lo primero es elegir el tipo de modelo a utilizar. La clase ``Sequential`` es la más sencilla y permite hacer redes neuronales feed-forward por capas con una única entrada y una única salida. La clase ``Model`` es más compleja y permite diseñar arquitecturas con varias entradas y salidas, bifurcaciones internas, etc.\n",
        "Para nuestros objetivos es suficiente con utilizar la clase ``Sequential``. Un MLP se define así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVEd_BqLxGHT"
      },
      "source": [
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "\n",
        "input_dim = X.shape[1:]\n",
        "output_dim = y.shape[1:] if len(y.shape) > 1 else 1\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=input_dim),\n",
        "    Dense(output_dim, activation='linear')\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osG_S0-QxGHU"
      },
      "source": [
        "Una vez definido, y a diferencia de lo que vimos en sklearn, un modelo keras debe ser compilado. En este paso se determinan el algoritmo de entrenamiento y los meta-parámetros relativos a este."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZWX7wHSxGHU"
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(), metrics=['mse', 'mae'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXKE62VGxGHU"
      },
      "source": [
        "Ahora el modelo se puede entrenar y evaluar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIv5FG9M0Epc",
        "outputId": "13a70c31-5694-47e2-e980-19a4fb7f169f"
      },
      "source": [
        "history = model.fit(X, y, batch_size=100, epochs=100, verbose=1, validation_split=0.1)\r\n",
        "\r\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "print('Test mse:', score[0])\r\n",
        "print('Test mae:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 147ms/step - loss: 1182703828966763.7500 - mse: 1182703828966763.7500 - mae: 17960855.7393 - val_loss: 1499170734080.0000 - val_mse: 1499170734080.0000 - val_mae: 1224406.2500\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1450266800947.2000 - mse: 1450266800947.2000 - mae: 1204051.2500 - val_loss: 1275438956544.0000 - val_mse: 1275438956544.0000 - val_mae: 1129353.3750\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1233833925017.6001 - mse: 1233833793945.6001 - mae: 1110578.7250 - val_loss: 1085096591360.0000 - val_mse: 1085096591360.0000 - val_mae: 1041679.8125\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1049699889971.2000 - mse: 1049699889971.2000 - mae: 1024362.3625 - val_loss: 923160281088.0000 - val_mse: 923160281088.0000 - val_mae: 960812.1875\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 893046226944.0000 - mse: 893046226944.0000 - mae: 944839.3125 - val_loss: 785390764032.0000 - val_mse: 785390764032.0000 - val_mae: 886222.8125\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 759770107084.8000 - mse: 759770107084.8000 - mae: 871489.3750 - val_loss: 668181397504.0000 - val_mse: 668181397504.0000 - val_mae: 817423.6875\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 646384700620.8000 - mse: 646384700620.8000 - mae: 803834.3125 - val_loss: 568464113664.0000 - val_mse: 568464113664.0000 - val_mae: 753965.6250\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 549919732531.2000 - mse: 549919732531.2000 - mae: 741430.9000 - val_loss: 483628417024.0000 - val_mse: 483628417024.0000 - val_mae: 695434.0000\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 467852256870.4000 - mse: 467852256870.4000 - mae: 683872.8625 - val_loss: 411453259776.0000 - val_mse: 411453259776.0000 - val_mae: 641446.1875\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 398031074099.2000 - mse: 398031074099.2000 - mae: 630782.3500 - val_loss: 350049402880.0000 - val_mse: 350049402880.0000 - val_mae: 591649.6875\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 338630338150.4000 - mse: 338630344704.0000 - mae: 581813.7125 - val_loss: 297809149952.0000 - val_mse: 297809149952.0000 - val_mae: 545718.9375\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 288093752524.8000 - mse: 288093752524.8000 - mae: 536646.0375 - val_loss: 253365010432.0000 - val_mse: 253365010432.0000 - val_mae: 503353.8125\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 245099633049.6000 - mse: 245099633049.6000 - mae: 494985.3312 - val_loss: 215553671168.0000 - val_mse: 215553671168.0000 - val_mae: 464277.5625\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 208522097459.2000 - mse: 208522097459.2000 - mae: 456559.1375 - val_loss: 183385194496.0000 - val_mse: 183385194496.0000 - val_mae: 428235.0312\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 177402911129.6000 - mse: 177402911129.6000 - mae: 421115.6375 - val_loss: 156017410048.0000 - val_mse: 156017410048.0000 - val_mae: 394990.3750\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 150927445196.8000 - mse: 150927451750.4000 - mae: 388423.1750 - val_loss: 132733878272.0000 - val_mse: 132733878272.0000 - val_mae: 364326.6250\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 128403613286.4000 - mse: 128403613286.4000 - mae: 358269.3500 - val_loss: 112925114368.0000 - val_mse: 112925114368.0000 - val_mae: 336043.3125\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 109241185075.2000 - mse: 109241185075.2000 - mae: 330456.4375 - val_loss: 96072556544.0000 - val_mse: 96072556544.0000 - val_mae: 309955.7188\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 92938395648.0000 - mse: 92938395648.0000 - mae: 304802.5187 - val_loss: 81735016448.0000 - val_mse: 81735016448.0000 - val_mae: 285893.3750\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 79068361523.2000 - mse: 79068356608.0000 - mae: 281139.8187 - val_loss: 69537169408.0000 - val_mse: 69537169408.0000 - val_mae: 263699.0000\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 67268408115.2000 - mse: 67268408115.2000 - mae: 259314.3813 - val_loss: 59159703552.0000 - val_mse: 59159703552.0000 - val_mae: 243227.6875\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 57229441433.6000 - mse: 57229441433.6000 - mae: 239183.2531 - val_loss: 50330910720.0000 - val_mse: 50330910720.0000 - val_mae: 224345.5156\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 48688725196.8000 - mse: 48688725196.8000 - mae: 220615.1063 - val_loss: 42819706880.0000 - val_mse: 42819706880.0000 - val_mae: 206929.2500\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 41422748057.6000 - mse: 41422748057.6000 - mae: 203488.7687 - val_loss: 36429455360.0000 - val_mse: 36429455360.0000 - val_mae: 190865.0156\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 35240888729.6000 - mse: 35240888729.6000 - mae: 187691.4250 - val_loss: 30992857088.0000 - val_mse: 30992857088.0000 - val_mae: 176047.8906\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 29981616537.6000 - mse: 29981616537.6000 - mae: 173120.4937 - val_loss: 26367598592.0000 - val_mse: 26367598592.0000 - val_mae: 162381.0312\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 25507137126.4000 - mse: 25507137126.4000 - mae: 159680.4937 - val_loss: 22432602112.0000 - val_mse: 22432602112.0000 - val_mae: 149775.1562\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 21700567449.6000 - mse: 21700567449.6000 - mae: 147284.3375 - val_loss: 19084845056.0000 - val_mse: 19084845056.0000 - val_mae: 138147.9062\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 18461963468.8000 - mse: 18461963468.8000 - mae: 135850.1125 - val_loss: 16236695552.0000 - val_mse: 16236695552.0000 - val_mae: 127423.2812\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 15706878361.6000 - mse: 15706878361.6000 - mae: 125304.2781 - val_loss: 13813600256.0000 - val_mse: 13813600256.0000 - val_mae: 117531.2578\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 13362785894.4000 - mse: 13362785894.4000 - mae: 115576.4922 - val_loss: 11752117248.0000 - val_mse: 11752117248.0000 - val_mae: 108407.1797\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 11368635392.0000 - mse: 11368635187.2000 - mae: 106604.3984 - val_loss: 9998282752.0000 - val_mse: 9998282752.0000 - val_mae: 99991.4141\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9671958118.4000 - mse: 9671958118.4000 - mae: 98328.2234 - val_loss: 8506182144.0000 - val_mse: 8506182144.0000 - val_mae: 92228.9688\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 8228473036.8000 - mse: 8228473036.8000 - mae: 90694.4500 - val_loss: 7236756992.0000 - val_mse: 7236756992.0000 - val_mae: 85069.1250\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7000496947.2000 - mse: 7000496947.2000 - mae: 83653.7641 - val_loss: 6156774912.0000 - val_mse: 6156774912.0000 - val_mae: 78465.1250\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5955783987.2000 - mse: 5955783987.2000 - mae: 77159.6906 - val_loss: 5237967872.0000 - val_mse: 5237967872.0000 - val_mae: 72373.8125\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5066982809.6000 - mse: 5066982809.6000 - mae: 71169.7984 - val_loss: 4456280576.0000 - val_mse: 4456280576.0000 - val_mae: 66755.3750\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4310761932.8000 - mse: 4310762035.2000 - mae: 65644.4609 - val_loss: 3791246336.0000 - val_mse: 3791246336.0000 - val_mae: 61573.0977\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3667472537.6000 - mse: 3667472537.6000 - mae: 60548.6445 - val_loss: 3225462528.0000 - val_mse: 3225462528.0000 - val_mae: 56793.1602\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3120147558.4000 - mse: 3120147558.4000 - mae: 55848.1242 - val_loss: 2744112128.0000 - val_mse: 2744112128.0000 - val_mae: 52384.2734\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2654528716.8000 - mse: 2654528665.6000 - mae: 51512.7414 - val_loss: 2334597376.0000 - val_mse: 2334597376.0000 - val_mae: 48317.6680\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2258323302.4000 - mse: 2258323302.4000 - mae: 47513.1875 - val_loss: 1986195968.0000 - val_mse: 1986195968.0000 - val_mae: 44566.7578\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1921327769.6000 - mse: 1921327769.6000 - mae: 43824.9766 - val_loss: 1689787392.0000 - val_mse: 1689787392.0000 - val_mae: 41107.0234\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1634623974.4000 - mse: 1634623974.4000 - mae: 40423.1148 - val_loss: 1437615104.0000 - val_mse: 1437615104.0000 - val_mae: 37915.8945\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1390631552.0000 - mse: 1390631628.8000 - mae: 37284.4008 - val_loss: 1223075840.0000 - val_mse: 1223075840.0000 - val_mae: 34972.5000\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1183119360.0000 - mse: 1183119385.6000 - mae: 34390.2414 - val_loss: 1040552320.0000 - val_mse: 1040552320.0000 - val_mae: 32257.5918\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1006554931.2000 - mse: 1006554931.2000 - mae: 31720.4727 - val_loss: 885267712.0000 - val_mse: 885267712.0000 - val_mae: 29753.4473\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 856332556.8000 - mse: 856332556.8000 - mae: 29257.8391 - val_loss: 753157376.0000 - val_mse: 753157376.0000 - val_mae: 27443.7109\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 728540044.8000 - mse: 728540044.8000 - mae: 26986.5711 - val_loss: 640763136.0000 - val_mse: 640763136.0000 - val_mae: 25313.2988\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 619825420.8000 - mse: 619825420.8000 - mae: 24891.7566 - val_loss: 545141504.0000 - val_mse: 545141504.0000 - val_mae: 23348.2637\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 527316051.2000 - mse: 527316051.2000 - mae: 22959.1832 - val_loss: 463789568.0000 - val_mse: 463789568.0000 - val_mae: 21535.7734\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 448612038.4000 - mse: 448612038.4000 - mae: 21176.6180 - val_loss: 394577984.0000 - val_mse: 394577984.0000 - val_mae: 19863.9844\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 381667667.2000 - mse: 381667667.2000 - mae: 19532.7641 - val_loss: 335695008.0000 - val_mse: 335695008.0000 - val_mae: 18321.9805\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 324708684.8000 - mse: 324708697.6000 - mae: 18016.4000 - val_loss: 285599744.0000 - val_mse: 285599744.0000 - val_mae: 16899.6953\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 276247430.4000 - mse: 276247443.2000 - mae: 16617.6719 - val_loss: 242979872.0000 - val_mse: 242979872.0000 - val_mae: 15587.8105\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 235023587.2000 - mse: 235023587.2000 - mae: 15327.6916 - val_loss: 206720832.0000 - val_mse: 206720832.0000 - val_mae: 14377.7881\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 199953212.8000 - mse: 199953212.8000 - mae: 14137.9027 - val_loss: 175872496.0000 - val_mse: 175872496.0000 - val_mae: 13261.6904\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 170117884.8000 - mse: 170117884.8000 - mae: 13040.5410 - val_loss: 149627936.0000 - val_mse: 149627936.0000 - val_mae: 12232.2480\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 144734112.0000 - mse: 144734108.8000 - mae: 12028.3420 - val_loss: 127299680.0000 - val_mse: 127299680.0000 - val_mae: 11282.7148\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 123126529.6000 - mse: 123126529.6000 - mae: 11094.2186 - val_loss: 108303656.0000 - val_mse: 108303656.0000 - val_mae: 10406.9023\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 104752388.8000 - mse: 104752388.8000 - mae: 10232.9934 - val_loss: 92142264.0000 - val_mse: 92142264.0000 - val_mae: 9599.0742\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 89118947.2000 - mse: 89118947.2000 - mae: 9438.5621 - val_loss: 78392704.0000 - val_mse: 78392704.0000 - val_mae: 8853.9629\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 75815379.2000 - mse: 75815379.2000 - mae: 8705.6217 - val_loss: 66694800.0000 - val_mse: 66694800.0000 - val_mae: 8166.6851\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 64507315.2000 - mse: 64507315.2000 - mae: 8030.1712 - val_loss: 56742724.0000 - val_mse: 56742724.0000 - val_mae: 7532.7744\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 54874848.0000 - mse: 54874848.0000 - mae: 7406.4076 - val_loss: 48275464.0000 - val_mse: 48275464.0000 - val_mae: 6948.0518\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 46690966.4000 - mse: 46690966.4000 - mae: 6831.8212 - val_loss: 41072092.0000 - val_mse: 41072092.0000 - val_mae: 6408.7485\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 39717742.4000 - mse: 39717742.4000 - mae: 6301.0521 - val_loss: 34943324.0000 - val_mse: 34943324.0000 - val_mae: 5911.2842\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 33792056.0000 - mse: 33792056.0000 - mae: 5812.0298 - val_loss: 29729348.0000 - val_mse: 29729348.0000 - val_mae: 5452.4585\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 28743938.8000 - mse: 28743938.8000 - mae: 5360.3730 - val_loss: 25293304.0000 - val_mse: 25293304.0000 - val_mae: 5029.2407\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 24460399.6000 - mse: 24460399.6000 - mae: 4944.8295 - val_loss: 21519298.0000 - val_mse: 21519298.0000 - val_mae: 4638.8857\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 20807976.0000 - mse: 20807976.0000 - mae: 4560.7395 - val_loss: 18308552.0000 - val_mse: 18308552.0000 - val_mae: 4278.8447\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 17702134.8000 - mse: 17702136.4000 - mae: 4206.6200 - val_loss: 15576865.0000 - val_mse: 15576865.0000 - val_mae: 3946.7485\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 15062100.6000 - mse: 15062100.6000 - mae: 3880.2720 - val_loss: 13252795.0000 - val_mse: 13252795.0000 - val_mae: 3640.4333\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 12815583.4000 - mse: 12815583.4000 - mae: 3579.2117 - val_loss: 11275475.0000 - val_mse: 11275475.0000 - val_mae: 3357.8914\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 10902270.6000 - mse: 10902270.6000 - mae: 3301.2422 - val_loss: 9593299.0000 - val_mse: 9593299.0000 - val_mae: 3097.2981\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9273074.2000 - mse: 9273073.6000 - mae: 3044.6107 - val_loss: 8161960.5000 - val_mse: 8161960.5000 - val_mae: 2856.9070\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7888902.1000 - mse: 7888902.1000 - mae: 2808.2030 - val_loss: 6944275.5000 - val_mse: 6944275.5000 - val_mae: 2635.1912\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6711981.6000 - mse: 6711981.6000 - mae: 2590.2700 - val_loss: 5908297.5000 - val_mse: 5908297.5000 - val_mae: 2430.6902\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5713080.7000 - mse: 5713080.7000 - mae: 2389.7365 - val_loss: 5026938.5000 - val_mse: 5026938.5000 - val_mae: 2242.0740\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4859363.3000 - mse: 4859363.3000 - mae: 2203.9686 - val_loss: 4277048.5000 - val_mse: 4277048.5000 - val_mae: 2068.0923\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4133076.5500 - mse: 4133076.6500 - mae: 2032.6099 - val_loss: 3639023.2500 - val_mse: 3639023.2500 - val_mae: 1907.6113\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3515537.5500 - mse: 3515537.5500 - mae: 1874.6244 - val_loss: 3096189.0000 - val_mse: 3096189.0000 - val_mae: 1759.5870\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2991590.0500 - mse: 2991590.0500 - mae: 1729.2843 - val_loss: 2634372.2500 - val_mse: 2634372.2500 - val_mae: 1623.0618\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2545983.2000 - mse: 2545983.2500 - mae: 1595.2911 - val_loss: 2241489.2500 - val_mse: 2241489.2500 - val_mae: 1497.1461\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2166458.0000 - mse: 2166457.8500 - mae: 1471.5796 - val_loss: 1907192.6250 - val_mse: 1907192.6250 - val_mae: 1380.9960\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1842248.8250 - mse: 1842248.8250 - mae: 1357.0176 - val_loss: 1622768.8750 - val_mse: 1622768.8750 - val_mae: 1273.8627\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1567547.0250 - mse: 1567547.0250 - mae: 1251.7511 - val_loss: 1380759.0000 - val_mse: 1380759.0000 - val_mae: 1175.0388\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1334250.0750 - mse: 1334250.0750 - mae: 1154.8411 - val_loss: 1174892.6250 - val_mse: 1174892.6250 - val_mae: 1083.9049\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1134092.3500 - mse: 1134092.3500 - mae: 1064.7081 - val_loss: 999694.0625 - val_mse: 999694.0625 - val_mae: 999.8256\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 965116.4125 - mse: 965116.4125 - mae: 982.1808 - val_loss: 850642.2500 - val_mse: 850642.2500 - val_mae: 922.2795\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 820922.1875 - mse: 820922.1875 - mae: 905.8443 - val_loss: 723849.2500 - val_mse: 723849.2500 - val_mae: 850.7682\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 698870.3625 - mse: 698870.3625 - mae: 835.7748 - val_loss: 615953.8750 - val_mse: 615953.8750 - val_mae: 784.8001\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 594636.3125 - mse: 594636.3125 - mae: 770.9286 - val_loss: 524143.0312 - val_mse: 524143.0312 - val_mae: 723.9478\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 505336.2875 - mse: 505336.2875 - mae: 710.6875 - val_loss: 446026.5938 - val_mse: 446026.5938 - val_mae: 667.8203\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 430592.7062 - mse: 430592.7062 - mae: 655.9993 - val_loss: 379573.8438 - val_mse: 379573.8438 - val_mae: 616.0610\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 366590.2125 - mse: 366590.2125 - mae: 605.2688 - val_loss: 323043.5000 - val_mse: 323043.5000 - val_mae: 568.3317\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 311520.7750 - mse: 311520.7750 - mae: 557.9560 - val_loss: 274916.9688 - val_mse: 274916.9688 - val_mae: 524.2846\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 265081.6562 - mse: 265081.6562 - mae: 514.6846 - val_loss: 233969.8750 - val_mse: 233969.8750 - val_mae: 483.6602\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 226046.7844 - mse: 226046.7844 - mae: 475.2467 - val_loss: 199133.4531 - val_mse: 199133.4531 - val_mae: 446.1959\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 192007.2625 - mse: 192007.2625 - mae: 437.9995 - val_loss: 169480.1250 - val_mse: 169480.1250 - val_mae: 411.6278\n",
            "Test mse: 168239.71875\n",
            "Test mae: 168239.71875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXMG7TAJxGHV"
      },
      "source": [
        "El resultado no es muy bueno, por varios motivos:\n",
        "\n",
        "* Los datos no se han estandarizado\n",
        "* El dataset tiene varios outliers concentrados hacia el final y sería recomendable hacer un particionado train-test aleatorio\n",
        "\n",
        "Sería conveniente poder aprovechar las utilidades de sklearn para resolver estos problemas. En versiones antiguas de keras existía un wrapper para hacerlo compatible con sklearn, pero ahora es necesario utilizar librerías externas para ello."
      ]
    }
  ]
}