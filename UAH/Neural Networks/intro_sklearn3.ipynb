{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "intro_sklearn3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBoj2RIq3LyU"
      },
      "source": [
        "# **Introducción a Scikit-learn**\r\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZuFTwsb3Lyb"
      },
      "source": [
        "### Selección automática de meta-parámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg9Acmj03Lyb"
      },
      "source": [
        "Habitualmente no se sabe de antemano la configuración óptima de los meta-parámetros (también llamados hiper-parámetros) de un modelo. Por ejemplo, en el modelo de k-vecinos visto anteriormente, no se sabe cuál es el valor óptimo de k.\n",
        "Sklearn ofrece algunas utilidades para automatizar mediante fuerza bruta este proceso:\n",
        "\n",
        "* GridSearchCV: permite definir explícitamente la rejilla en el espacio de meta-parámetros que se quiere explorar.\n",
        "* RandomizedSearchCV: permite asignar distribuciones de probabilidad a los distintos meta-parámetros a explorar y prueba un número acotado de configuraciones posibles definidas por estas distribuciones.\n",
        "\n",
        "GridSearchCV suele ser buena opción cuando hay pocos meta-parámetros a explorar y no tienen muchos valores posibles. Si el espacio de búsqueda es grande, sin embargo, su coste es excesivo y se prefiere RandomizedSearchCV, que tiene un coste acotado.\n",
        "\n",
        "Existen alternativas un poco mejores que la simple fuerza bruta (ver BayesSearchCV de scikit-optimize), que generalmente son mejoras sobre RandomizedSearchCV en las que en lugar de buscar aleatoriamente se exploran regiones interesantes del espacio de meta-parámetros, pero en cualquier caso el proceso pasa por evaluar una gran cantidad de posibles configuraciones del modelo, multiplicando el coste con respecto al entrenamiento de una única configuración."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbc07rkF3Lyc"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3cVJbzx3Lyd"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "predictor = KNeighborsClassifier()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubD8KTX73Lyd"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seNj9fw13Lye"
      },
      "source": [
        "search_space = {\"n_neighbors\": [1, 3, 5, 7, 9, 11]}\n",
        "estimator = GridSearchCV(predictor, search_space)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ArwmvZ73Lye",
        "outputId": "9ed0a6c4-e6e8-44e3-fb2d-8c45c15b767d"
      },
      "source": [
        "estimator.fit(X, y)\n",
        "print(f\"Best hyper-params: {estimator.best_params_}\\nBest accuracy: {estimator.best_score_}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best hyper-params: {'n_neighbors': 7}\n",
            "Best accuracy: 0.9800000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSgwhuk83Lyf"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "predictor = RandomForestClassifier()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcN6hc2q3Lyf"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ed-0jfT3Lyg"
      },
      "source": [
        "search_space = {\"n_estimators\": randint(1, 100),\n",
        "                \"criterion\": [\"gini\", \"entropy\"],\n",
        "                \"max_depth\": [2, 4, 8]}\n",
        "estimator = RandomizedSearchCV(predictor, search_space, n_iter=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO8_eL7t3Lyg",
        "outputId": "4af8fa41-7fc0-4d73-e38e-9b724fa5d4f3"
      },
      "source": [
        "estimator.fit(X, y)\n",
        "print(f\"Best hyper-params: {estimator.best_params_}\\nBest accuracy: {estimator.best_score_}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best hyper-params: {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 96}\n",
            "Best accuracy: 0.9666666666666668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWpVBDNN3Lyh"
      },
      "source": [
        "### Construcción de un modelo compatible con sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8ujGSQ23Lyi"
      },
      "source": [
        "En ocasiones el modelo buscado no está disponible en sklearn y no queda más opción que programarlo. En estos casos, es recomendable hacerlo compatible con sklearn para aprovechar todas las utilidades adicionales que la librería ofrece, como búsquedas de meta-parámetros, pipelines, cross-validators, métricas, etc.\n",
        "\n",
        "Toda clase compatible con sklearn debe heredar de la clase BaseEstimator, y, en función de su objetivo, de al menos una de las clases siguientes:\n",
        "* RegressorMixin\n",
        "* ClassifierMixin\n",
        "* ClusterMixin\n",
        "* TransformerMixin\n",
        "\n",
        "Además, debe implementar los métodos __init__, fit, score y predict (RegressorMixin, ClassifierMixin y ClusterMixin) o transform (TransformerMixin)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvxbCssH3Lyj"
      },
      "source": [
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class OLSRegressor(BaseEstimator, RegressorMixin):\n",
        "\n",
        "    # Este modelo no tiene meta-parámetros, así que no requiere modificar el __init__ heredado de BaseEstimator\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if len(X.shape) == 1: X = x.reshape((-1, 1))\n",
        "        ones = np.ones((len(X), 1))\n",
        "        X_bias = np.append(ones, X, axis=1)\n",
        "        self.beta_ = X_inv @ X2 # Aquí se calcula Beta a partir de X_bias e y\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if len(X.shape) == 1: X = x.reshape((-1, 1))\n",
        "        ones = np.ones((len(X), 1))\n",
        "        X_bias = np.append(ones, X, axis=1)\n",
        "        preds = X @ self.beta_ # Aquí se calculan las predicciones a partir de X_bias y self.beta_\n",
        "        return preds\n",
        "    \n",
        "    def score(self,X,y):\n",
        "        preds = self.predict(X)\n",
        "        return r2_score(y,preds)\n",
        "\n",
        "    # Este modelo no requiere una definición de score distinta de la r2 heredada de RegressorMixin"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyktBFxS3Lyk"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Adzb4M3Lyk"
      },
      "source": [
        "X1 = X.T @ X"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_g0r33K3Lyk",
        "outputId": "62e91b3d-b901-4eeb-845d-ccf9434c47cd"
      },
      "source": [
        "X_inv= np.linalg.inv(X1)\n",
        "X_inv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.05034014, -0.0564344 , -0.04649057,  0.04508845],\n",
              "       [-0.0564344 ,  0.06736108,  0.04506042, -0.03745986],\n",
              "       [-0.04649057,  0.04506042,  0.06696879, -0.09831163],\n",
              "       [ 0.04508845, -0.03745986, -0.09831163,  0.18358105]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAAzflPL3Lyl",
        "outputId": "a3185c18-6c29-4436-b840-99c32c7e68aa"
      },
      "source": [
        "X2 = (X.T @ y)\n",
        "X2"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([955.6, 435.9, 768.2, 268.9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eis-EKz3Lym",
        "outputId": "d722f444-dbde-4143-bab3-2fa4f5439d60"
      },
      "source": [
        "X_inv @ X2"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0844926 , -0.02356211,  0.22487123,  0.59972247])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C2KYiY43Lym"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}